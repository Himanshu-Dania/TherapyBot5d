{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 22:06:03.908758: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-16 22:06:04.773596: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-16 22:06:04.773732: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-16 22:06:04.892757: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-16 22:06:05.146782: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-16 22:06:07.369822: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am feeling depressed because of my mom [{\"label\": \"sadness\", \"score\": 0.804105818271637}, {\"label\": \"disappointment\", \"score\": 0.2157609462738037}, {\"label\": \"neutral\", \"score\": 0.02382960543036461}, {\"label\": \"annoyance\", \"score\": 0.021625010296702385}, {\"label\": \"realization\", \"score\": 0.012930833734571934}, {\"label\": \"grief\", \"score\": 0.012079876847565174}, {\"label\": \"disapproval\", \"score\": 0.00969152431935072}, {\"label\": \"nervousness\", \"score\": 0.00935348216444254}, {\"label\": \"approval\", \"score\": 0.009168700315058231}, {\"label\": \"remorse\", \"score\": 0.008994612842798233}, {\"label\": \"joy\", \"score\": 0.007684770505875349}, {\"label\": \"love\", \"score\": 0.005724872462451458}, {\"label\": \"anger\", \"score\": 0.005535678938031197}, {\"label\": \"caring\", \"score\": 0.004993458744138479}, {\"label\": \"admiration\", \"score\": 0.004297302104532719}, {\"label\": \"amusement\", \"score\": 0.0038930100854486227}, {\"label\": \"fear\", \"score\": 0.0031285672448575497}, {\"label\": \"disgust\", \"score\": 0.002900524064898491}, {\"label\": \"confusion\", \"score\": 0.002820538356900215}, {\"label\": \"desire\", \"score\": 0.002782169496640563}, {\"label\": \"curiosity\", \"score\": 0.002734270179644227}, {\"label\": \"embarrassment\", \"score\": 0.0024641226045787334}, {\"label\": \"optimism\", \"score\": 0.0023715251591056585}, {\"label\": \"relief\", \"score\": 0.002085750689730048}, {\"label\": \"surprise\", \"score\": 0.0019533110316842794}, {\"label\": \"excitement\", \"score\": 0.0017509760800749063}, {\"label\": \"gratitude\", \"score\": 0.0012392281787469983}, {\"label\": \"pride\", \"score\": 0.00043108215322718024}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import json\n",
    "import os\n",
    "key=os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "emotion_model = pipeline(\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", token=key)\n",
    "\n",
    "while True:\n",
    "    query=input()\n",
    "    if query==\"exit\": break\n",
    "    print(query, json.dumps(emotion_model(query, top_k=28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy, neutral, approval, relief, admiration, excitement, gratitude, caring, amusement, love, optimism, realization, annoyance, disapproval, sadness, pride, confusion, anger, desire, disappointment, curiosity, nervousness, surprise, remorse, grief, embarrassment, fear, disgust, "
     ]
    }
   ],
   "source": [
    "ans=emotion_model(\"I am happy\", top_k=28)   \n",
    "for i in range(28):\n",
    "    print(ans[i][\"label\"], end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'confusion', 'score': 0.9218111038208008},\n",
       " {'label': 'neutral', 'score': 0.0905587300658226},\n",
       " {'label': 'realization', 'score': 0.05267453193664551}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_model(\"You're asking how I am, honestly I don't even know anymore\", top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e948c62a01e47e5b0a390fde169d4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  38%|###8      | 839M/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at heegyu/TinyLlama-augesc-context-strategy and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "device=\"cuda:0\"\n",
    "model = \"heegyu/TinyLlama-augesc-context-strategy\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model).eval().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1740, 0.0569, 0.0956, 0.2178, 0.1346, 0.1829, 0.0739, 0.0644]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Self-disclosure\n"
     ]
    }
   ],
   "source": [
    "\n",
    "example = \"\"\"usr: Hi\n",
    "sys[Question]: Hello, how are you today?\n",
    "usr: I'm feeling anxious that I am going to lose my job.\"\"\"\n",
    "\n",
    "inputs = tokenizer(example, return_tensors=\"pt\").to(device)\n",
    "logits = model(**inputs).logits.softmax(-1)\n",
    "print(logits)\n",
    "\n",
    "label = logits.argmax(-1).item()\n",
    "\n",
    "\n",
    "ESCONV_STRATEGY = [\n",
    "    \"Question\",\n",
    "    \"Restatement or Paraphrasing\",\n",
    "    \"Reflection of feelings\",\n",
    "    \"Self-disclosure\",\n",
    "    \"Affirmation and Reassurance\",\n",
    "    \"Providing Suggestions\",\n",
    "    \"Information\",\n",
    "    \"Others\"\n",
    "]\n",
    "id2label = {i:k for i, k in enumerate(ESCONV_STRATEGY)}\n",
    "\n",
    "print(id2label[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Question',\n",
       " 1: 'Restatement or Paraphrasing',\n",
       " 2: 'Reflection of feelings',\n",
       " 3: 'Self-disclosure',\n",
       " 4: 'Affirmation and Reassurance',\n",
       " 5: 'Providing Suggestions',\n",
       " 6: 'Information',\n",
       " 7: 'Others'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {i:k for i, k in enumerate(ESCONV_STRATEGY)}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a51305fff343bf97e7ac6b04635cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/510 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de326da14f7a46dfb8c159909d6dbb87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781b62d18bc5412880c63595ffebf571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/865k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4544bbf49e9248159f42bb62518e75e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/881k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7497d6f1299242f294793f3d463462e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b2ddbc951443e795bce4e5ed928ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f19dc50c71470999ee57865081b316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"thu-coai/esconv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 910\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 195\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 195\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"experience_type\": \"Current Experience\", \"emotion_type\": \"anxiety\", \"problem_type\": \"job crisis\", \"situation\": \"I am on short term disability and I am afraid I will lose my job if I don\\'t go back soon.\", \"survey_score\": {\"seeker\": {\"initial_emotion_intensity\": \"3\", \"empathy\": \"5\", \"relevance\": \"5\", \"final_emotion_intensity\": \"2\"}, \"supporter\": {\"relevance\": \"5\"}}, \"dialog\": [{\"text\": \"Hello good afternoon.\", \"speaker\": \"usr\"}, {\"text\": \"Hi, good afternoon.\", \"speaker\": \"sys\", \"strategy\": \"Question\"}, {\"text\": \"I\\'m feeling anxious that I am going to lose my job.\", \"speaker\": \"usr\"}, {\"text\": \"Losing a job is always anxious.\", \"speaker\": \"sys\", \"strategy\": \"Reflection of feelings\"}, {\"text\": \"I hope I don\\'t.\", \"speaker\": \"usr\"}, {\"text\": \"Why do you think you will lose your job?\", \"speaker\": \"sys\", \"strategy\": \"Question\"}, {\"text\": \"I am on short term disability and I am not ready to go back to work yet but I do not have any job protection.\", \"speaker\": \"usr\"}, {\"text\": \"Oh so your job is not protected and your short term disability will end soon? Is that correct?\", \"speaker\": \"sys\", \"strategy\": \"Restatement or Paraphrasing\"}, {\"text\": \"It\\'s not ending yet, but no my job is not protected. I live in the United States, but I have not been at my job long enough to earn protection for medical leave.\", \"speaker\": \"usr\"}, {\"text\": \"you have to have been here for a year, and I started November 2020\", \"speaker\": \"usr\"}, {\"text\": \"I\\'m afraid that I will lose my job since I\\'m still on disability for the foreseeable future.\", \"speaker\": \"usr\"}, {\"text\": \"I see. Have you spoken to HR?\", \"speaker\": \"sys\", \"strategy\": \"Providing Suggestions\"}, {\"text\": \"I have, but they are telling me that it is up to my department manager who isn\\'t actually getting back to me about it yet.\", \"speaker\": \"usr\"}, {\"text\": \"Your department manager is not answering you?\", \"speaker\": \"sys\", \"strategy\": \"Restatement or Paraphrasing\"}, {\"text\": \"No, I have sent them a few emails about it. It makes me nervous. I do not have a phone number to call and my psychiatrist really does not think I am ready to go back to the stress of my job.\", \"speaker\": \"usr\"}, {\"text\": \"I wish I could just call him, but I do not have a phone number for him. Just his email.\", \"speaker\": \"usr\"}, {\"text\": \"Have you tried mentioning that to HR?\", \"speaker\": \"sys\", \"strategy\": \"Providing Suggestions\"}, {\"text\": \"HR is the one who gave me his email.\", \"speaker\": \"usr\"}, {\"text\": \"I don\\'t think he has a direct work line, and they\\'re not allowed to give out personal information.\", \"speaker\": \"usr\"}, {\"text\": \"Yes that is how most employments work about providing personal information.\", \"speaker\": \"sys\", \"strategy\": \"Information\"}, {\"text\": \"That in itself causes anxiety to most since other forms of communication is not possible especially if they are not responding to ciritcal matters.\", \"speaker\": \"sys\", \"strategy\": \"Reflection of feelings\"}, {\"text\": \"Yes! 100%. Every time my phone rings I get nervous that I\\'m being fired and I\\'m worried I made a mistake going out on disability. I needed to though, but I\\'m nervous.\", \"speaker\": \"usr\"}, {\"text\": \"No you should not have to feel you made a mistake for the time you are taking out of work for a necessity.\", \"speaker\": \"sys\", \"strategy\": \"Affirmation and Reassurance\"}, {\"text\": \"Thank you for saying that. That does make me feel better. It sucks sometimes we have to choose between our health and our jobs. We don\\'t get paid to take care of our health though, we only get paid to work.\", \"speaker\": \"usr\"}, {\"text\": \"You know yourself more than anybody and you need to take care of yourself.\", \"speaker\": \"sys\", \"strategy\": \"Others\"}], \"seeker_question1\": \"They did a great job, but should\\'ve asked why I\\'m out on disability to get more context.\", \"seeker_question2\": \"N.A\", \"supporter_question1\": \"I enjoyed helping someone in need\", \"supporter_question2\": \"\"}',\n",
       " '{\"experience_type\": \"Current Experience\", \"emotion_type\": \"depression\", \"problem_type\": \"ongoing depression\", \"situation\": \"I have been in a depression since my father died last year. We have had to sell our home and move to a much smaller place due to losing his income. I am older but lived with my parents to help them because they are both ill. it has been an ongoing struggle\", \"survey_score\": {\"seeker\": {\"initial_emotion_intensity\": \"4\", \"empathy\": \"4\", \"relevance\": \"5\", \"final_emotion_intensity\": \"3\"}, \"supporter\": {\"relevance\": \"5\"}}, \"dialog\": [{\"text\": \"How are you doing today?\", \"speaker\": \"sys\", \"strategy\": \"Question\"}, {\"text\": \"hello I am ok how are you?\", \"speaker\": \"usr\"}, {\"text\": \"I am well, what\\'s on your mind?\", \"speaker\": \"sys\", \"strategy\": \"Question\"}, {\"text\": \"well as I stated above my father passed last year and now due to finances we need to move. I am out of work due to Covid19 it is hard moving not being able to support my family\", \"speaker\": \"usr\"}, {\"text\": \"So sorry to hear about your plight. Life is a roller coaster and sometimes it gets out of control, I hope things slow down so you can get things straightened out.\", \"speaker\": \"sys\", \"strategy\": \"Affirmation and Reassurance\"}, {\"text\": \"thank you! I find myself so stressed then I get scared and depressed wondering what will the future hold will we be ok will we take another hit will I get sick will my Mother be ok\", \"speaker\": \"usr\"}, {\"text\": \"I understand your concerns about being stressed, scared and depressed. The risk of family getting sick is certainly valid.\", \"speaker\": \"sys\", \"strategy\": \"Restatement or Paraphrasing\"}, {\"text\": \"it keeps me up at night and I cant seem to get away form it even for a moment\", \"speaker\": \"usr\"}, {\"text\": \"I too worry about things I feel I cannot control, the lack of sleep due to this just makes it worse so I try to think of positive things, but its hard.\", \"speaker\": \"sys\", \"strategy\": \"Self-disclosure\"}, {\"text\": \"yes and its always in the back of my mind burning. Like don\\'t be to happy because things are going to fail\", \"speaker\": \"usr\"}, {\"text\": \"Its hard to stop those negative thoughts, but the first step is sharing your feelings with others and talking about it. You are now on your way to healing.\", \"speaker\": \"sys\", \"strategy\": \"Affirmation and Reassurance\"}, {\"text\": \"It does help to talk about it with someone who doesn\\'t judge\", \"speaker\": \"usr\"}, {\"text\": \"I can see in your words how stressed you are and troubled.\", \"speaker\": \"sys\", \"strategy\": \"Reflection of feelings\"}, {\"text\": \"This whole covid thing makes it 10 times worse\", \"speaker\": \"usr\"}, {\"text\": \"May I suggest that you seek some face to face support from a best friend or close family member.\", \"speaker\": \"sys\", \"strategy\": \"Information\"}, {\"text\": \"easier said then done I\\'m high risk so I have been social distancing\", \"speaker\": \"usr\"}, {\"text\": \"Its still possible. Social distancing, six feet away but in maybe your backyard or even a park away from others so you can talk with some degree of confidence that its private. Just being around another person is so very supportive and positive. Please try.\", \"speaker\": \"sys\", \"strategy\": \"Information\"}, {\"text\": \"maybe but I need to be carful plus honest I dont want many people to know about my feelings\", \"speaker\": \"usr\"}, {\"text\": \"True. Remember, you are not the only one facing these troubles, others are tackling it too. Try also to google online support groups on Reddit and blogs for additional assistance and suggestions from those who faced it and succeeded. Doing what others did to overcome it means not having to reinvent the whole process on your own.\", \"speaker\": \"sys\", \"strategy\": \"Providing Suggestions\"}, {\"text\": \"maybe an online chat group\", \"speaker\": \"usr\"}, {\"text\": \"That\\'s the way to go. Keep seeking help. The right solution is there for you. Now you have a plan to get started.\", \"speaker\": \"sys\", \"strategy\": \"Affirmation and Reassurance\"}, {\"text\": \"well I don\\'t know if its a plan but an idea just knowing I\\'m not alone helps\", \"speaker\": \"usr\"}, {\"text\": \"Yes, it a problem so many people are facing.\", \"speaker\": \"sys\", \"strategy\": \"Reflection of feelings\"}, {\"text\": \"My own family members are facing this too.\", \"speaker\": \"sys\", \"strategy\": \"Self-disclosure\"}, {\"text\": \"yes I know and with covid so many are depressed stressed and sad\", \"speaker\": \"usr\"}, {\"text\": \"I read a few articles on Psychology today website that might help you also. They discuss how to control stress and overcome depression in this world of COVID. Written by some doctors and they are free to read.\", \"speaker\": \"sys\", \"strategy\": \"Information\"}, {\"text\": \"thanks I will have to look online take your suggestion\", \"speaker\": \"usr\"}, {\"text\": \"You are welcome. You are on your way.\", \"speaker\": \"sys\", \"strategy\": \"Affirmation and Reassurance\"}, {\"text\": \"thank you for your kind words\", \"speaker\": \"usr\"}, {\"text\": \"It was my pleasure.\", \"speaker\": \"sys\", \"strategy\": \"Others\"}, {\"text\": \"I will look online for the info you suggested I will see if maybe I can talk to a friend if we can do safely thanks again\", \"speaker\": \"usr\"}], \"seeker_question1\": \"it was a good task kind of makes you look at your self\", \"seeker_question2\": \"no was a good one thank you\", \"supporter_question1\": \"The guidance as to how to structure the conversation helped me frame my advice.\", \"supporter_question2\": \"I wish I could have used emoji\\'s to add some additional emotional graphics to my text.\"}',\n",
       " '{\"experience_type\": \"Current Experience\", \"emotion_type\": \"anxiety\", \"problem_type\": \"job crisis\", \"situation\": \"I would like to get an online job  but it is very competitive.\", \"survey_score\": {\"seeker\": {\"initial_emotion_intensity\": \"5\", \"empathy\": \"5\", \"relevance\": \"4\", \"final_emotion_intensity\": \"3\"}, \"supporter\": {\"relevance\": \"3\"}}, \"dialog\": [{\"text\": \"I feel obligated to help you this Christmas Night.\", \"speaker\": \"sys\", \"strategy\": \"Reflection of feelings\"}, {\"text\": \"Hello Hello\", \"speaker\": \"usr\"}, {\"text\": \"Who am I currently speaking with?\", \"speaker\": \"sys\", \"strategy\": \"Question\"}, {\"text\": \"I am Bob, your Christmas Night therapist and helper.\", \"speaker\": \"sys\", \"strategy\": \"Self-disclosure\"}, {\"text\": \"I hope I can assist you this Christmas Night.\", \"speaker\": \"sys\", \"strategy\": \"Reflection of feelings\"}, {\"text\": \"It takes courage to tell how you are feeling.\", \"speaker\": \"sys\", \"strategy\": \"Information\"}, {\"text\": \"Hello Bob, nice to meet you\", \"speaker\": \"usr\"}, {\"text\": \"I would like to talk but not sure if I can I will try\", \"speaker\": \"usr\"}, {\"text\": \"How can I help you?\", \"speaker\": \"sys\", \"strategy\": \"Question\"}, {\"text\": \"I am a caregiver and i can only come back and forth\", \"speaker\": \"usr\"}, {\"text\": \"Please do your best. That is all I can expect.\", \"speaker\": \"sys\", \"strategy\": \"Affirmation and Reassurance\"}, {\"text\": \"Can you elaborate? What do you mean by that?\", \"speaker\": \"sys\", \"strategy\": \"Question\"}, {\"text\": \"You\\'re doing great by contributing to your own cause on Christmas Night.\", \"speaker\": \"sys\", \"strategy\": \"Affirmation and Reassurance\"}, {\"text\": \"Do you like Christmas cookies?\", \"speaker\": \"sys\", \"strategy\": \"Question\"}, {\"text\": \"My main job started so i am in this room an at the same time i wan to do mTurk and take care of them]\", \"speaker\": \"usr\"}, {\"text\": \"Bob has some jelly cookies for you.\", \"speaker\": \"sys\", \"strategy\": \"Information\"}, {\"text\": \"I feel good asking you about how I can give you true insights on life.\", \"speaker\": \"sys\", \"strategy\": \"Reflection of feelings\"}, {\"text\": \"You made the right decision to join and discuss your feelings. Do you like the Christmas Holidays?\", \"speaker\": \"sys\", \"strategy\": \"Affirmation and Reassurance\"}, {\"text\": \"I can suggest Uber or Lyft or Door Dash or Grub Hub for you.\", \"speaker\": \"sys\", \"strategy\": \"Providing Suggestions\"}, {\"text\": \"I feel that you can earn and not be so sad and depressed this holiday.\", \"speaker\": \"sys\", \"strategy\": \"Reflection of feelings\"}, {\"text\": \"I am baking cookies for others, so don\\'t feel sad. Maybe I can cheer you up with chocolate chip cookies.\", \"speaker\": \"sys\", \"strategy\": \"Self-disclosure\"}, {\"text\": \"I am here to help you in soooo many ways.\", \"speaker\": \"sys\", \"strategy\": \"Self-disclosure\"}, {\"text\": \"that is wonderful\", \"speaker\": \"usr\"}, {\"text\": \"I love chocolate chip cookie\", \"speaker\": \"usr\"}, {\"text\": \"thanks for your encouragemnt\", \"speaker\": \"usr\"}, {\"text\": \"I think that already helped,e\", \"speaker\": \"usr\"}, {\"text\": \"Yes, it is. I love chocoalate chip.\", \"speaker\": \"sys\", \"strategy\": \"Reflection of feelings\"}, {\"text\": \"Do you have the chance to make Christmas Cookies?\", \"speaker\": \"sys\", \"strategy\": \"Question\"}, {\"text\": \"Perhaps you could bake some using Bob\\'s Xmas Cookie Recipe and share the joy that Christmas brings to the World.\", \"speaker\": \"sys\", \"strategy\": \"Providing Suggestions\"}, {\"text\": \"Would you be interested?\", \"speaker\": \"sys\", \"strategy\": \"Question\"}, {\"text\": \"not today but sometime this week.\", \"speaker\": \"usr\"}, {\"text\": \"oh nice 1\", \"speaker\": \"usr\"}, {\"text\": \"yes please\", \"speaker\": \"usr\"}, {\"text\": \"Cooking cookies for others is a great way to cheer up. You could also create a small business by making your own type of cookies.\", \"speaker\": \"sys\", \"strategy\": \"Information\"}, {\"text\": \"I made oatmeal cookie last week. I love baking\", \"speaker\": \"usr\"}, {\"text\": \"wonderful, i would pay $ to buy Bob\\'s cookie\", \"speaker\": \"usr\"}, {\"text\": \"You said you love baking? Well, other people who see you love to cook will get Joy from you. : )\", \"speaker\": \"sys\", \"strategy\": \"Restatement or Paraphrasing\"}, {\"text\": \"nice, thank you\", \"speaker\": \"usr\"}, {\"text\": \"I feel good to share my insights.\", \"speaker\": \"sys\", \"strategy\": \"Reflection of feelings\"}, {\"text\": \"yes I love it. I put 2 cups of sugar all the time.\", \"speaker\": \"usr\"}, {\"text\": \"2 sticks ofbutter\", \"speaker\": \"usr\"}, {\"text\": \"Did you need any other insights from me to be glad?\", \"speaker\": \"sys\", \"strategy\": \"Question\"}, {\"text\": \"I feel that being a professional baker my be the right career for you!\", \"speaker\": \"sys\", \"strategy\": \"Reflection of feelings\"}, {\"text\": \"I am full, and I am good\", \"speaker\": \"usr\"}, {\"text\": \"thanks it was great to talk to you Bob, Xmas couselor\", \"speaker\": \"usr\"}, {\"text\": \"Do you need help with anything else?\", \"speaker\": \"sys\", \"strategy\": \"Question\"}, {\"text\": \"I will think about it\", \"speaker\": \"usr\"}, {\"text\": \"im good, have a good evening\", \"speaker\": \"usr\"}, {\"text\": \"I feel that you are on your way to a new cooking career.\", \"speaker\": \"sys\", \"strategy\": \"Reflection of feelings\"}], \"seeker_question1\": \"no\", \"seeker_question2\": \"no\", \"supporter_question1\": \"I think that is was a vague issue that the seeker was asking for help with.\", \"supporter_question2\": \"I think that there should be a push notification to continue talking with a message in red that blinks on the screen near the chat box.\"}',\n",
       " '{\"experience_type\": \"Current Experience\", \"emotion_type\": \"depression\", \"problem_type\": \"breakup with partner\", \"situation\": \"turned in ex gf to cps for giving her kids drugs.\", \"survey_score\": {\"seeker\": {\"initial_emotion_intensity\": \"5\", \"empathy\": \"3\", \"relevance\": \"2\", \"final_emotion_intensity\": \"4\"}, \"supporter\": {\"relevance\": \"5\"}}, \"dialog\": [{\"text\": \"Hello! Hope you are doing well. How may I assist you?\", \"speaker\": \"sys\", \"strategy\": \"Question\"}, {\"text\": \"my recent ex gf gave her daughters drugs while on a video chat with me. While being very dishonest in our relationship, i am devestated about the truth of all of it now that its over. I really loved her. and her kids. we had some great times. I turned her in for giving her kids drugs as thats not okay.\", \"speaker\": \"usr\"}, {\"text\": \"today im super sad. i dont have any motivation. I dont want to really be around, and im trapped in my thoughts with everything. i had to move to get away from her stalking me. now im in a new place trying to find a job and get set up here. Its difficult to start over.\", \"speaker\": \"usr\"}, {\"text\": \"its a pretty intense situation i admit.\", \"speaker\": \"usr\"}, {\"text\": \"You are girlfriend is giving drugs to hew own kids. Did I get it right?\", \"speaker\": \"sys\", \"strategy\": \"Restatement or Paraphrasing\"}, {\"text\": \"That is what she did. Among many other things.\", \"speaker\": \"usr\"}, {\"text\": \"That is really intense, unacceptable. I am feeling sorry for the poor little girl and you. It looks like there is something wrong with her. I can understand what you are going through.\", \"speaker\": \"sys\", \"strategy\": \"Affirmation and Reassurance\"}, {\"text\": \"Its a difficult time. I want to do nothing. It feels very bleek right now worrying about finances and getting set up in a new state.\", \"speaker\": \"usr\"}, {\"text\": \"It must be hard time for you. You should not worry about her. You should think about your job and the poor girl who is trapped with her.\", \"speaker\": \"sys\", \"strategy\": \"Reflection of feelings\"}, {\"text\": \"her daughters now both live with their dads. so thats taken care of, he kids are safer and better off. I however am devastated that the whole relationship wound up a lie and the whole thing has me really in a bad place mentally.\", \"speaker\": \"usr\"}, {\"text\": \"I felt the same way when I broke up with my friend for some pathetic things which she did. The good part is girls are safe now. Give some time to yourself. Time will heal everything.\", \"speaker\": \"sys\", \"strategy\": \"Self-disclosure\"}, {\"text\": \"Thats a hard light to see at the end of the tunnel when things are bleek.\", \"speaker\": \"usr\"}, {\"text\": \"im not sure what else to do.\", \"speaker\": \"usr\"}, {\"text\": \"My mind runs away a bit right now, its just all stress ful\", \"speaker\": \"usr\"}, {\"text\": \"So sorry to hear about that. You should indulge yourself in some activities like yoga or meditation.\", \"speaker\": \"sys\", \"strategy\": \"Others\"}, {\"text\": \"talk to your family and friends and go to them for a while. It will help you and you can come out of it.\", \"speaker\": \"sys\", \"strategy\": \"Affirmation and Reassurance\"}, {\"text\": \"Finding a better job.\", \"speaker\": \"usr\"}, {\"text\": \"might be a more productive task.\", \"speaker\": \"usr\"}, {\"text\": \"You will get one soon. Keep working on. My best wishes are there with you. Time never stay the same.\", \"speaker\": \"sys\", \"strategy\": \"Others\"}, {\"text\": \"you dont want to continue to talk\", \"speaker\": \"usr\"}, {\"text\": \"No, that is not the case. You can talk as much as you want.\", \"speaker\": \"sys\", \"strategy\": \"Restatement or Paraphrasing\"}, {\"text\": \"I see. i thought you had left.\", \"speaker\": \"usr\"}, {\"text\": \"No I am hear and thinking of you and trying to figure out how can you come out of it.\", \"speaker\": \"sys\", \"strategy\": \"Others\"}], \"seeker_question1\": \"\", \"seeker_question2\": \"\", \"supporter_question1\": \"\", \"supporter_question2\": \"\"}',\n",
       " '{\"experience_type\": \"Previous Experience\", \"emotion_type\": \"disgust\", \"problem_type\": \"problems with friends\", \"situation\": \"one of my friends cheated on her boyfriend.\", \"survey_score\": {\"seeker\": {\"initial_emotion_intensity\": \"5\", \"empathy\": \"5\", \"relevance\": \"5\", \"final_emotion_intensity\": \"2\"}, \"supporter\": {\"relevance\": \"5\"}}, \"dialog\": [{\"text\": \"Hi can you help me with my problem?\", \"speaker\": \"usr\"}, {\"text\": \"Hello. What\\'s on your mind?\", \"speaker\": \"sys\", \"strategy\": \"Question\"}, {\"text\": \"I\\'m disgusted with my friend for cheating on her boyfriend. Am I right to feel this way?\", \"speaker\": \"usr\"}, {\"text\": \"Your feelings are valid, no matter what they are.\", \"speaker\": \"sys\", \"strategy\": \"Affirmation and Reassurance\"}, {\"text\": \"Why do you think you\\'re disgusted with her?\", \"speaker\": \"sys\", \"strategy\": \"Question\"}, {\"text\": \"Because she\\'s not acting the way she should be acting.\", \"speaker\": \"usr\"}, {\"text\": \"Her boyfriend is a nice guy so he doesn\\'t deserve this treatment\", \"speaker\": \"usr\"}, {\"text\": \"It sounds like she did something you find really immoral.\", \"speaker\": \"sys\", \"strategy\": \"Reflection of feelings\"}, {\"text\": \"Is their relationship generally pretty good, to your knowledge?\", \"speaker\": \"sys\", \"strategy\": \"Question\"}, {\"text\": \"Yeah, but I\\'m also thinking it\\'s not my business. I should just stay out of it.\", \"speaker\": \"usr\"}, {\"text\": \"Well I thought it was good until that happened. He doesn\\'t know. So I just feel gross around them.\", \"speaker\": \"usr\"}, {\"text\": \"Have you talked to your friend about what she did?\", \"speaker\": \"sys\", \"strategy\": \"Question\"}, {\"text\": \"Yeah, she doesn\\'t really care because she\\'s not going to tell him. I\\'m questioning whether I should still be friends with her.\", \"speaker\": \"usr\"}, {\"text\": \"You\\'re definite right to be questioning if this is the sort of person you want to be friends with.\", \"speaker\": \"sys\", \"strategy\": \"Affirmation and Reassurance\"}, {\"text\": \"It\\'s hard to stop thought because we work at the same place.\", \"speaker\": \"usr\"}, {\"text\": \"though..\", \"speaker\": \"usr\"}, {\"text\": \"If her behavior is getting to you like this, I definitely suggest you try to keep some distance from her as much as you can.\", \"speaker\": \"sys\", \"strategy\": \"Providing Suggestions\"}, {\"text\": \"Yeah, I\\'ve been trying to, but she\\'s always talking to me\", \"speaker\": \"usr\"}, {\"text\": \"It might be a good idea to explain why you\\'re upset with her, even though that\\'s likely to upset her.\", \"speaker\": \"sys\", \"strategy\": \"Providing Suggestions\"}, {\"text\": \"I guess, but I\\'d rather just avoid her.\", \"speaker\": \"usr\"}, {\"text\": \"I\\'m thinking if I ignore her then she\", \"speaker\": \"usr\"}, {\"text\": \"she\\'ll get the hint\", \"speaker\": \"usr\"}, {\"text\": \"I can definitely understand wanting to avoid a confrontation.\", \"speaker\": \"sys\", \"strategy\": \"Reflection of feelings\"}, {\"text\": \"Yeah, I realize she\\'s quite selfish so confronting her wouldn\\'t help.\", \"speaker\": \"usr\"}, {\"text\": \"What do you think you can do to minimize your contact with her?\", \"speaker\": \"sys\", \"strategy\": \"Question\"}, {\"text\": \"Just not respond to her messages and avoid the areas she\\'s in\", \"speaker\": \"usr\"}, {\"text\": \"That sounds like a good plan.\", \"speaker\": \"sys\", \"strategy\": \"Affirmation and Reassurance\"}, {\"text\": \"Is that ghosting?\", \"speaker\": \"usr\"}, {\"text\": \"What one person calls ghosting, someone else can call looking out for yourself.\", \"speaker\": \"sys\", \"strategy\": \"Information\"}, {\"text\": \"It sounds like she knows why you\\'re upset with her and would be able to understand why you\\'re choosing not to talk to her.\", \"speaker\": \"sys\", \"strategy\": \"Reflection of feelings\"}, {\"text\": \"If she\\'s not interested in listening to you or thinking about what she\\'s done, then you need to be doing what is best for you in cutting her out.\", \"speaker\": \"sys\", \"strategy\": \"Providing Suggestions\"}], \"seeker_question1\": \"no\", \"seeker_question2\": \"15 minutes takes too long, 10 message count is better to quit on.\", \"supporter_question1\": \"I find this live communication really enjoyable.\", \"supporter_question2\": \"\"}']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=ds[\"train\"][\"text\"]\n",
    "test_data = (ds[\"test\"][\"text\"])\n",
    "validation_data = (ds[\"validation\"][\"text\"])\n",
    "\n",
    "# data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c']\n"
     ]
    }
   ],
   "source": [
    "l=[\"a\",\"b\"]\n",
    "l.extend([\"c\"])\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "':' expected after dictionary key (963566968.py, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 35\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"emot\"\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m ':' expected after dictionary key\n"
     ]
    }
   ],
   "source": [
    "# #REDO because they are not in usr-sys order always!\n",
    "\n",
    "# import pandas as pd\n",
    "# import json\n",
    "\n",
    "# # test_data = json.loads(test_data)\n",
    "\n",
    "# # Initialize variables for test_dataFrame construction\n",
    "# rows = []\n",
    "# session_id = 1\n",
    "\n",
    "# # Parse the test_data\n",
    "# for entry in data:\n",
    "#     entry=json.loads(entry)\n",
    "#     problem_type = entry.get(\"problem_type\")\n",
    "#     emotion_type = entry.get(\"emotion_type\")\n",
    "#     situation = entry.get(\"situation\")\n",
    "\n",
    "#     # Iterate over dialog entries in pairs\n",
    "#     dialog = entry[\"dialog\"]\n",
    "#     tmp={\n",
    "#         \"text\":\"\",\n",
    "#         \"strategy\":[],\n",
    "#         \"speaker\":\"\"\n",
    "#     }\n",
    "#     for text in dialog:\n",
    "#         if text[\"speaker\"]==\"usr\" and tmp[\"speaker\"]!=\"sys\":\n",
    "#             tmp[\"speaker\"]+=\" \"+text[\"text\"]\n",
    "            \n",
    "#         elif text[\"speaker\"]==\"sys\" and tmp[\"speaker\"]!=\"usr\":\n",
    "#             tmp[\"strategy\"].append(text[\"strategy\"])\n",
    "#         else:\n",
    "#             rows.append({\n",
    "#                 \"problem\": problem_type,\n",
    "#                 \"emot\"\n",
    "#             })\n",
    "#             tmp=tmp={\n",
    "#                 \"text\":\"\",\n",
    "#                 \"strategy\":[],\n",
    "#                 \"speaker\":\"\"\n",
    "#             }\n",
    "        \n",
    "            \n",
    "    \n",
    "#     session_id += 1\n",
    "\n",
    "# # Convert to DataFrame\n",
    "# df = pd.DataFrame(rows)\n",
    "\n",
    "# # Display the DataFrame\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: usr: Hello good afternoon.\n",
      "Label: ['Question']\n",
      "------\n",
      "Text: usr: Hello good afternoon. sys(Question): Hi, good afternoon. usr: I'm feeling anxious that I am going to lose my job.\n",
      "Label: ['Reflection of feelings']\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Suppose your raw data is stored in the variable `data`\n",
    "# where each element is a JSON string (one conversation per line).\n",
    "# For example:\n",
    "# data = [\n",
    "#    '{\"experience_type\": \"Current Experience\", \"emotion_type\": \"anxiety\", ... }',\n",
    "#    '{\"experience_type\": \"...\", ... }',\n",
    "#    ...\n",
    "# ]\n",
    "\n",
    "training_samples = []  # To store the transformed examples\n",
    "\n",
    "for line in data:\n",
    "    # Parse the JSON for one conversation\n",
    "    conv = json.loads(line)\n",
    "    dialog = conv[\"dialog\"]\n",
    "\n",
    "    # First, merge consecutive utterances by the same speaker.\n",
    "    merged_blocks = []  # Each block is a dict: {speaker, text, [strategies]}\n",
    "    for utt in dialog:\n",
    "        speaker = utt[\"speaker\"].strip()\n",
    "        text = utt[\"text\"].strip()\n",
    "        strategy = utt.get(\"strategy\")  # might be None for user turns\n",
    "\n",
    "        if merged_blocks and merged_blocks[-1][\"speaker\"] == speaker:\n",
    "            # Same speaker as previous block → merge texts.\n",
    "            merged_blocks[-1][\"text\"] += \" \" + text\n",
    "            # For system turns, if a strategy is present, add it to the list.\n",
    "            if speaker == \"sys\" and strategy:\n",
    "                merged_blocks[-1][\"strategies\"].append(strategy)\n",
    "        else:\n",
    "            # Start a new block.\n",
    "            if speaker == \"sys\":\n",
    "                # For sys blocks, store the strategy in a list.\n",
    "                merged_blocks.append({\n",
    "                    \"speaker\": speaker,\n",
    "                    \"text\": text,\n",
    "                    \"strategies\": [strategy] if strategy else []\n",
    "                })\n",
    "            else:\n",
    "                merged_blocks.append({\n",
    "                    \"speaker\": speaker,\n",
    "                    \"text\": text\n",
    "                })\n",
    "\n",
    "    # Next, generate training samples.\n",
    "    # The idea is: for each system (sys) block (which carries a strategy),\n",
    "    # create a sample whose input text is the conversation history _before_ that sys block.\n",
    "    for i, block in enumerate(merged_blocks):\n",
    "        if block[\"speaker\"] == \"sys\" and block.get(\"strategies\"):\n",
    "            # Build the conversation context from all previous blocks.\n",
    "            context_parts = []\n",
    "            for b in merged_blocks[:i]:\n",
    "                if b[\"speaker\"] == \"usr\":\n",
    "                    context_parts.append(f\"usr: {b['text']}\")\n",
    "                elif b[\"speaker\"] == \"sys\":\n",
    "                    # Join the strategies with a comma if there are multiple.\n",
    "                    strat = \", \".join(b.get(\"strategies\", []))\n",
    "                    context_parts.append(f\"sys({strat}): {b['text']}\")\n",
    "            context = \" \".join(context_parts).strip()\n",
    "\n",
    "            # The label is the strategy (or list of strategies) from the current sys block.\n",
    "            training_samples.append({\n",
    "                \"text\": context,\n",
    "                \"label\": block[\"strategies\"]\n",
    "            })\n",
    "\n",
    "# Optionally, save the transformed data as a CSV (each row: text, label)\n",
    "df = pd.DataFrame(training_samples)\n",
    "df.to_csv(\"transformed_dataset.csv\", index=False)\n",
    "\n",
    "# For inspection, print the first few samples:\n",
    "for sample in training_samples[:2]:\n",
    "    print(\"Text:\", sample[\"text\"])\n",
    "    print(\"Label:\", sample[\"label\"])\n",
    "    print(\"------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14642, 8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>user_text</th>\n",
       "      <th>sys_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hello good afternoon.</td>\n",
       "      <td>Hi, good afternoon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm feeling anxious that I am going to lose my...</td>\n",
       "      <td>Losing a job is always anxious.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I hope I don't.</td>\n",
       "      <td>Why do you think you will lose your job?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>I am on short term disability and I am not rea...</td>\n",
       "      <td>Oh so your job is not protected and your short...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm afraid that I will lose my job since I'm s...</td>\n",
       "      <td>I see. Have you spoken to HR?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>I have, but they are telling me that it is up ...</td>\n",
       "      <td>Your department manager is not answering you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>I wish I could just call him, but I do not hav...</td>\n",
       "      <td>Have you tried mentioning that to HR?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>I don't think he has a direct work line, and t...</td>\n",
       "      <td>Yes that is how most employments work about pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes! 100%. Every time my phone rings I get ner...</td>\n",
       "      <td>No you should not have to feel you made a mist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Thank you for saying that. That does make me f...</td>\n",
       "      <td>You know yourself more than anybody and you ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>hello I am ok how are you?</td>\n",
       "      <td>I am well, what's on your mind?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>well as I stated above my father passed last y...</td>\n",
       "      <td>So sorry to hear about your plight. Life is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>thank you! I find myself so stressed then I ge...</td>\n",
       "      <td>I understand your concerns about being stresse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>it keeps me up at night and I cant seem to get...</td>\n",
       "      <td>I too worry about things I feel I cannot contr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>yes and its always in the back of my mind burn...</td>\n",
       "      <td>Its hard to stop those negative thoughts, but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>It does help to talk about it with someone who...</td>\n",
       "      <td>I can see in your words how stressed you are a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>This whole covid thing makes it 10 times worse</td>\n",
       "      <td>May I suggest that you seek some face to face ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>easier said then done I'm high risk so I have ...</td>\n",
       "      <td>Its still possible. Social distancing, six fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>maybe but I need to be carful plus honest I do...</td>\n",
       "      <td>True. Remember, you are not the only one facin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>maybe an online chat group</td>\n",
       "      <td>That's the way to go. Keep seeking help. The r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session_id                                          user_text  \\\n",
       "0            1                              Hello good afternoon.   \n",
       "1            1  I'm feeling anxious that I am going to lose my...   \n",
       "2            1                                    I hope I don't.   \n",
       "3            1  I am on short term disability and I am not rea...   \n",
       "4            1  I'm afraid that I will lose my job since I'm s...   \n",
       "5            1  I have, but they are telling me that it is up ...   \n",
       "6            1  I wish I could just call him, but I do not hav...   \n",
       "7            1  I don't think he has a direct work line, and t...   \n",
       "8            1  Yes! 100%. Every time my phone rings I get ner...   \n",
       "9            1  Thank you for saying that. That does make me f...   \n",
       "10           2                         hello I am ok how are you?   \n",
       "11           2  well as I stated above my father passed last y...   \n",
       "12           2  thank you! I find myself so stressed then I ge...   \n",
       "13           2  it keeps me up at night and I cant seem to get...   \n",
       "14           2  yes and its always in the back of my mind burn...   \n",
       "15           2  It does help to talk about it with someone who...   \n",
       "16           2     This whole covid thing makes it 10 times worse   \n",
       "17           2  easier said then done I'm high risk so I have ...   \n",
       "18           2  maybe but I need to be carful plus honest I do...   \n",
       "19           2                         maybe an online chat group   \n",
       "\n",
       "                                             sys_text  \n",
       "0                                 Hi, good afternoon.  \n",
       "1                     Losing a job is always anxious.  \n",
       "2            Why do you think you will lose your job?  \n",
       "3   Oh so your job is not protected and your short...  \n",
       "4                       I see. Have you spoken to HR?  \n",
       "5       Your department manager is not answering you?  \n",
       "6               Have you tried mentioning that to HR?  \n",
       "7   Yes that is how most employments work about pr...  \n",
       "8   No you should not have to feel you made a mist...  \n",
       "9   You know yourself more than anybody and you ne...  \n",
       "10                    I am well, what's on your mind?  \n",
       "11  So sorry to hear about your plight. Life is a ...  \n",
       "12  I understand your concerns about being stresse...  \n",
       "13  I too worry about things I feel I cannot contr...  \n",
       "14  Its hard to stop those negative thoughts, but ...  \n",
       "15  I can see in your words how stressed you are a...  \n",
       "16  May I suggest that you seek some face to face ...  \n",
       "17  Its still possible. Social distancing, six fee...  \n",
       "18  True. Remember, you are not the only one facin...  \n",
       "19  That's the way to go. Keep seeking help. The r...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"session_id\", \"user_text\", \"sys_text\"]][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is very useful has problem, emotion(if finetuning krni ho), and a thing called strategy which is related to empathy and therapeutic convos so we could fit a model for that, there is one but it has B parameters or 2gb, too big for our problem(i think) need a smaller one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next dataset is AugESC which is aaugmented(ai generated) using ESC dataset although it doesn't have strategy , its only slightly useful and the dataset is not for use other than research tasks but lets see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total conversations: 611849\n",
      "\n",
      "First few rows:\n",
      "   session_id                                          user_text  \\\n",
      "0           1  My upstairs neighbors make a ton of noise at a...   \n",
      "1           1  I'm not sure if they're directly in my room, b...   \n",
      "2           1  They have what sounds like parties, loud music...   \n",
      "3           1  The only thing I've found that helps a little ...   \n",
      "4           1  I've complained to my landlord but haven't had...   \n",
      "\n",
      "                                            sys_text  \n",
      "0  Ah, I understand, there's more noise in your a...  \n",
      "1  What sort of noise do you hear? Do you feel th...  \n",
      "2  I can see how it may be difficult to sleep at ...  \n",
      "3  Have you tried asking them to turn their music...  \n",
      "4  I would imagine that they don't care much abou...  \n",
      "\n",
      "Unique sessions: 65077\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"thu-coai/augesc\")\n",
    "\n",
    "# Initialize lists\n",
    "user_texts = []\n",
    "sys_texts = []\n",
    "session_ids = []\n",
    "\n",
    "# Process each conversation in the dataset\n",
    "for idx, text in enumerate(dataset[\"train\"][\"text\"], start=1):\n",
    "    # Convert string representation to list\n",
    "    conversation = ast.literal_eval(text)\n",
    "    \n",
    "    # Extract messages\n",
    "    for i in range(0, len(conversation), 2):\n",
    "        if i + 1 < len(conversation):\n",
    "            if conversation[i][0] == \"usr\" and conversation[i+1][0] == \"sys\":\n",
    "                user_texts.append(conversation[i][1])\n",
    "                sys_texts.append(conversation[i+1][1])\n",
    "                session_ids.append(idx)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'session_id': session_ids,\n",
    "    'user_text': user_texts,\n",
    "    'sys_text': sys_texts\n",
    "})\n",
    "\n",
    "print(f\"Total conversations: {len(df)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nUnique sessions: {df['session_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>user_text</th>\n",
       "      <th>sys_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>My upstairs neighbors make a ton of noise at a...</td>\n",
       "      <td>Ah, I understand, there's more noise in your a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm not sure if they're directly in my room, b...</td>\n",
       "      <td>What sort of noise do you hear? Do you feel th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>They have what sounds like parties, loud music...</td>\n",
       "      <td>I can see how it may be difficult to sleep at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The only thing I've found that helps a little ...</td>\n",
       "      <td>Have you tried asking them to turn their music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I've complained to my landlord but haven't had...</td>\n",
       "      <td>I would imagine that they don't care much abou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id                                          user_text  \\\n",
       "0           1  My upstairs neighbors make a ton of noise at a...   \n",
       "1           1  I'm not sure if they're directly in my room, b...   \n",
       "2           1  They have what sounds like parties, loud music...   \n",
       "3           1  The only thing I've found that helps a little ...   \n",
       "4           1  I've complained to my landlord but haven't had...   \n",
       "\n",
       "                                            sys_text  \n",
       "0  Ah, I understand, there's more noise in your a...  \n",
       "1  What sort of noise do you hear? Do you feel th...  \n",
       "2  I can see how it may be difficult to sleep at ...  \n",
       "3  Have you tried asking them to turn their music...  \n",
       "4  I would imagine that they don't care much abou...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File is not a zip file\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Download dataset from Google Drive\n",
    "url = 'https://drive.google.com/file/d/15KjSeYn3tjiHXiswLgffmxPEoMYtepv2'  # Replace with actual file ID\n",
    "output = 'SMILE_DATASET_v2.zip'\n",
    "\n",
    "try:\n",
    "    # Download if file doesn't exist\n",
    "    if not os.path.exists(output):\n",
    "        gdown.download(url, output, quiet=False)\n",
    "    \n",
    "    # Extract ZIP\n",
    "    with zipfile.ZipFile(output, 'r') as zip_ref:\n",
    "        zip_ref.extractall('smile_data')\n",
    "    \n",
    "    # Load dataset\n",
    "    df = pd.read_csv('smile_data/SMILE_DATASET_v2.csv')  # Adjust path if different\n",
    "    \n",
    "    print(\"Dataset shape:\", df.shape)\n",
    "    print(\"\\nColumns:\", df.columns.tolist())\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc372ef149d94c22b143627c2c50c13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/2.82k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03eb29171dfc47c594a775074fbe51e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.79M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ac57053aad494985a1c166c719f5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Context', 'Response'],\n",
       "        num_rows: 3512\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=load_dataset(\"Amod/mental_health_counseling_conversations\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>user_text</th>\n",
       "      <th>sys_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>If everyone thinks you're worthless, then mayb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>Hello, and thank you for your question and see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>First thing I'd suggest is getting the sleep y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>Therapy is essential for those that are feelin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>I first want to let you know that you are not ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id                                          user_text  \\\n",
       "0           1  I'm going through some things with my feelings...   \n",
       "1           2  I'm going through some things with my feelings...   \n",
       "2           3  I'm going through some things with my feelings...   \n",
       "3           4  I'm going through some things with my feelings...   \n",
       "4           5  I'm going through some things with my feelings...   \n",
       "\n",
       "                                            sys_text  \n",
       "0  If everyone thinks you're worthless, then mayb...  \n",
       "1  Hello, and thank you for your question and see...  \n",
       "2  First thing I'd suggest is getting the sleep y...  \n",
       "3  Therapy is essential for those that are feelin...  \n",
       "4  I first want to let you know that you are not ...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\n",
    "    \"session_id\":range(1, len(data[\"train\"])+1), \n",
    "    \"user_text\": data[\"train\"][\"Context\"], \n",
    "    \"sys_text\": data[\"train\"][\"Response\"]\n",
    "    })\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize BigQuery client\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mbigquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# SQL query\u001b[39;00m\n\u001b[1;32m      9\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124mSELECT author, body, score, created_utc\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124mFROM `fh-bigquery.reddit_comments.2015_05`\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124mLIMIT 1000  # Adjust limit as needed\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/bigquery/client.py:243\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, project, credentials, _http, location, default_query_job_config, default_load_job_config, client_info, client_options)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    234\u001b[0m     project\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m     client_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    242\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 243\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mClient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_http\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_http\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m     kw_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: client_info}\n\u001b[1;32m    251\u001b[0m     bq_host \u001b[38;5;241m=\u001b[39m _get_bigquery_host()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/client/__init__.py:320\u001b[0m, in \u001b[0;36mClientWithProject.__init__\u001b[0;34m(self, project, credentials, client_options, _http)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, project\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, credentials\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, client_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, _http\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 320\u001b[0m     \u001b[43m_ClientProjectMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     Client\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28mself\u001b[39m, credentials\u001b[38;5;241m=\u001b[39mcredentials, client_options\u001b[38;5;241m=\u001b[39mclient_options, _http\u001b[38;5;241m=\u001b[39m_http\n\u001b[1;32m    323\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/client/__init__.py:268\u001b[0m, in \u001b[0;36m_ClientProjectMixin.__init__\u001b[0;34m(self, project, credentials)\u001b[0m\n\u001b[1;32m    265\u001b[0m     project \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(credentials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m project \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     project \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_determine_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m project \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProject was not passed and could not be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetermined from the environment.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/client/__init__.py:287\u001b[0m, in \u001b[0;36m_ClientProjectMixin._determine_default\u001b[0;34m(project)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_determine_default\u001b[39m(project):\n\u001b[1;32m    286\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper:  use default project detection.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_determine_default_project\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/_helpers/__init__.py:152\u001b[0m, in \u001b[0;36m_determine_default_project\u001b[0;34m(project)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Determine default project ID explicitly or implicitly as fall-back.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03mSee :func:`google.auth.default` for details on how the default project\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m:returns: Default project if it can be determined.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m project \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     _, project \u001b[38;5;241m=\u001b[39m \u001b[43mgoogle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m project\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/auth/_default.py:691\u001b[0m, in \u001b[0;36mdefault\u001b[0;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[1;32m    683\u001b[0m             _LOGGER\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    684\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo project ID could be determined. Consider running \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    685\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    686\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    687\u001b[0m                 environment_vars\u001b[38;5;241m.\u001b[39mPROJECT,\n\u001b[1;32m    688\u001b[0m             )\n\u001b[1;32m    689\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[0;32m--> 691\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/himanshu/.local/lib/python3.10/site-packages (4.47.1)\n",
      "Requirement already satisfied: torch in /home/himanshu/.local/lib/python3.10/site-packages (2.3.1)\n",
      "Requirement already satisfied: lm-format-enforcer in /home/himanshu/.local/lib/python3.10/site-packages (0.10.3)\n",
      "Requirement already satisfied: huggingface_hub in /home/himanshu/.local/lib/python3.10/site-packages (0.27.0)\n",
      "Requirement already satisfied: optimum in /home/himanshu/.local/lib/python3.10/site-packages (1.23.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/himanshu/.local/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: requests in /home/himanshu/.local/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/himanshu/.local/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/himanshu/.local/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/himanshu/.local/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/himanshu/.local/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/himanshu/.local/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/himanshu/.local/lib/python3.10/site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: filelock in /home/himanshu/.local/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/himanshu/.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: jinja2 in /home/himanshu/.local/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/himanshu/.local/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/himanshu/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/himanshu/.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/himanshu/.local/lib/python3.10/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: triton==2.3.1 in /home/himanshu/.local/lib/python3.10/site-packages (from torch) (2.3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/himanshu/.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/himanshu/.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/himanshu/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/himanshu/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/himanshu/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/himanshu/.local/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/himanshu/.local/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/himanshu/.local/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/himanshu/.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: sympy in /home/himanshu/.local/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/himanshu/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.2.140)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in /home/himanshu/.local/lib/python3.10/site-packages (from lm-format-enforcer) (2.8.2)\n",
      "Requirement already satisfied: interegular>=0.3.2 in /home/himanshu/.local/lib/python3.10/site-packages (from lm-format-enforcer) (0.3.3)\n",
      "Requirement already satisfied: coloredlogs in /home/himanshu/.local/lib/python3.10/site-packages (from optimum) (15.0.1)\n",
      "Requirement already satisfied: datasets in /home/himanshu/.local/lib/python3.10/site-packages (from optimum) (2.17.1)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/himanshu/.local/lib/python3.10/site-packages (from pydantic>=1.10.8->lm-format-enforcer) (2.20.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/himanshu/.local/lib/python3.10/site-packages (from pydantic>=1.10.8->lm-format-enforcer) (0.7.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/himanshu/.local/lib/python3.10/site-packages (from coloredlogs->optimum) (10.0)\n",
      "Requirement already satisfied: xxhash in /home/himanshu/.local/lib/python3.10/site-packages (from datasets->optimum) (3.4.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/himanshu/.local/lib/python3.10/site-packages (from datasets->optimum) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/himanshu/.local/lib/python3.10/site-packages (from datasets->optimum) (0.6)\n",
      "Requirement already satisfied: multiprocess in /home/himanshu/.local/lib/python3.10/site-packages (from datasets->optimum) (0.70.15)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/himanshu/.local/lib/python3.10/site-packages (from datasets->optimum) (0.3.7)\n",
      "Requirement already satisfied: aiohttp in /home/himanshu/.local/lib/python3.10/site-packages (from datasets->optimum) (3.9.1)\n",
      "Requirement already satisfied: pandas in /home/himanshu/.local/lib/python3.10/site-packages (from datasets->optimum) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/himanshu/.local/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/himanshu/.local/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/himanshu/.local/lib/python3.10/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/himanshu/.local/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/himanshu/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/himanshu/.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/himanshu/.local/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/himanshu/.local/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/himanshu/.local/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.9.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/himanshu/.local/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/himanshu/.local/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/himanshu/.local/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/himanshu/.local/lib/python3.10/site-packages (from pandas->datasets->optimum) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/himanshu/.local/lib/python3.10/site-packages (from pandas->datasets->optimum) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/himanshu/.local/lib/python3.10/site-packages (from pandas->datasets->optimum) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://huggingface.github.io/autogptq-index/whl/cu118/\n",
      "Requirement already satisfied: auto-gptq in /home/himanshu/.local/lib/python3.10/site-packages (0.7.1+cu118)\n",
      "Requirement already satisfied: tqdm in /home/himanshu/.local/lib/python3.10/site-packages (from auto-gptq) (4.66.5)\n",
      "Requirement already satisfied: numpy in /home/himanshu/.local/lib/python3.10/site-packages (from auto-gptq) (1.26.0)\n",
      "Requirement already satisfied: peft>=0.5.0 in /home/himanshu/.local/lib/python3.10/site-packages (from auto-gptq) (0.11.1)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /home/himanshu/.local/lib/python3.10/site-packages (from auto-gptq) (0.30.1)\n",
      "Requirement already satisfied: gekko in /home/himanshu/.local/lib/python3.10/site-packages (from auto-gptq) (1.1.3)\n",
      "Requirement already satisfied: rouge in /home/himanshu/.local/lib/python3.10/site-packages (from auto-gptq) (1.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/himanshu/.local/lib/python3.10/site-packages (from auto-gptq) (2.3.1)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /home/himanshu/.local/lib/python3.10/site-packages (from auto-gptq) (4.47.1)\n",
      "Requirement already satisfied: datasets in /home/himanshu/.local/lib/python3.10/site-packages (from auto-gptq) (2.17.1)\n",
      "Requirement already satisfied: safetensors in /home/himanshu/.local/lib/python3.10/site-packages (from auto-gptq) (0.4.2)\n",
      "Requirement already satisfied: sentencepiece in /home/himanshu/.local/lib/python3.10/site-packages (from auto-gptq) (0.2.0)\n",
      "Requirement already satisfied: psutil in /home/himanshu/.local/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (5.9.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/himanshu/.local/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (24.1)\n",
      "Requirement already satisfied: huggingface-hub in /home/himanshu/.local/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (0.27.0)\n",
      "Requirement already satisfied: pyyaml in /home/himanshu/.local/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (6.0.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/himanshu/.local/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (8.9.2.26)\n",
      "Requirement already satisfied: sympy in /home/himanshu/.local/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (1.12)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/himanshu/.local/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/himanshu/.local/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/himanshu/.local/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (2.20.5)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/himanshu/.local/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /home/himanshu/.local/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.1.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/himanshu/.local/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/himanshu/.local/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/himanshu/.local/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/himanshu/.local/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/himanshu/.local/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (10.3.2.106)\n",
      "Requirement already satisfied: fsspec in /home/himanshu/.local/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/himanshu/.local/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /home/himanshu/.local/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (2.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/himanshu/.local/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\n",
      "Requirement already satisfied: filelock in /home/himanshu/.local/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/himanshu/.local/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/himanshu/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->auto-gptq) (12.2.140)\n",
      "Requirement already satisfied: requests in /home/himanshu/.local/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/himanshu/.local/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (0.21.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/himanshu/.local/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (2023.12.25)\n",
      "Requirement already satisfied: pandas in /home/himanshu/.local/lib/python3.10/site-packages (from datasets->auto-gptq) (2.2.2)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/himanshu/.local/lib/python3.10/site-packages (from datasets->auto-gptq) (15.0.0)\n",
      "Requirement already satisfied: xxhash in /home/himanshu/.local/lib/python3.10/site-packages (from datasets->auto-gptq) (3.4.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/himanshu/.local/lib/python3.10/site-packages (from datasets->auto-gptq) (0.3.7)\n",
      "Requirement already satisfied: aiohttp in /home/himanshu/.local/lib/python3.10/site-packages (from datasets->auto-gptq) (3.9.1)\n",
      "Requirement already satisfied: multiprocess in /home/himanshu/.local/lib/python3.10/site-packages (from datasets->auto-gptq) (0.70.15)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/himanshu/.local/lib/python3.10/site-packages (from datasets->auto-gptq) (0.6)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from rouge->auto-gptq) (1.16.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/himanshu/.local/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/himanshu/.local/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/himanshu/.local/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.4.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/himanshu/.local/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/himanshu/.local/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/himanshu/.local/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.9.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/himanshu/.local/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/himanshu/.local/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/himanshu/.local/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/himanshu/.local/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (3.3.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/himanshu/.local/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.5)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/himanshu/.local/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/himanshu/.local/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/himanshu/.local/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2.9.0.post0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/himanshu/.local/lib/python3.10/site-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch lm-format-enforcer huggingface_hub optimum\n",
    "!pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07 20:57:33.243157: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-07 20:57:34.060979: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-07 20:57:34.061066: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-07 20:57:34.205878: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-07 20:57:34.498488: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-07 20:57:36.540187: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Requirements if running from Google Colab with a T4 GPU. \n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from lmformatenforcer import JsonSchemaParser\n",
    "from lmformatenforcer.integrations.transformers import build_transformers_prefix_allowed_tokens_fn\n",
    "from transformers import pipeline\n",
    "\n",
    "class AnswerFormat(BaseModel):\n",
    "    user_emotion: str = Field(..., description=\"User's emotion while writing the query.\", example=\"A mix of relief, regret and sadness\")\n",
    "    user_problem: str = Field(..., description=\"The problem/issue user is facing\", example=\"self identity crisis\")\n",
    "    strategy: str = Field(..., description=\"Strategy to be used to answer user's query\", example=\"A mix of Affirmation and Reassurance and Providing Suggestions\")\n",
    "    output: str = Field(..., description=\"An output to be sent to the user\")\n",
    "    \n",
    "# Create a transformers pipeline\n",
    "\n",
    "hf_pipeline = pipeline('text-generation', model='microsoft/DialoGPT-large')\n",
    "\n",
    "# Create a character level parser and build a transformers prefix function from it\n",
    "parser = JsonSchemaParser(AnswerFormat.model_json_schema())\n",
    "prefix_function = build_transformers_prefix_allowed_tokens_fn(hf_pipeline.tokenizer, parser)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'user_emotion': {'description': \"User's emotion while writing the query.\",\n",
       "   'example': 'A mix of relief, regret and sadness',\n",
       "   'title': 'User Emotion',\n",
       "   'type': 'string'},\n",
       "  'user_problem': {'description': 'The problem/issue user is facing',\n",
       "   'example': 'self identity crisis',\n",
       "   'title': 'User Problem',\n",
       "   'type': 'string'},\n",
       "  'strategy': {'description': \"Strategy to be used to answer user's query\",\n",
       "   'example': 'A mix of Affirmation and Reassurance and Providing Suggestions',\n",
       "   'title': 'Strategy',\n",
       "   'type': 'string'},\n",
       "  'output': {'description': 'An output to be sent to the user',\n",
       "   'title': 'Output',\n",
       "   'type': 'string'}},\n",
       " 'required': ['user_emotion', 'user_problem', 'strategy', 'output'],\n",
       " 'title': 'AnswerFormat',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AnswerFormat.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            {\"strategy\" :\n"
     ]
    }
   ],
   "source": [
    "query= \"hi\"\n",
    "# input(\"Enter the query: \")\n",
    "prompt = f'''Your task is find out the following things regarding user's query.\n",
    "User's emotion, \n",
    "User's problem(eg. job crisis, loneliness etc), \n",
    "A therapy strategy that will help the user the most(eg.\n",
    "\"Questioning to make them open up\",\n",
    "\"Restatement or Paraphrasing\",\n",
    "\"Reflection of feelings\",\n",
    "\"Self-disclosure\",\n",
    "\"Affirmation and Reassurance\",\n",
    "\"Providing Suggestions\"),\n",
    "Along with this, generate a human-like empathetic message\n",
    "\n",
    "Provide the result in this schema:\n",
    "{AnswerFormat.model_json_schema()}\n",
    "\n",
    "Query: {query}\n",
    "Answer:\\n\n",
    "'''\n",
    "\n",
    "# Call the pipeline with the prefix function\n",
    "output_dict = hf_pipeline(prompt, prefix_allowed_tokens_fn=prefix_function)\n",
    "\n",
    "# Extract the results\n",
    "result = output_dict[0]['generated_text'][len(prompt):]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Your task is find out the following things regarding user\\'s query.\\nUser\\'s emotion, \\nUser\\'s problem(eg. job crisis, loneliness etc), \\nA therapy strategy that will help the user the most(eg.\\n\"Questioning to make them open up\",\\n\"Restatement or Paraphrasing\",\\n\"Reflection of feelings\",\\n\"Self-disclosure\",\\n\"Affirmation and Reassurance\",\\n\"Providing Suggestions\"),\\nAlong with this, generate a human-like empathetic message\\n\\nProvide the result in this schema:\\n{\\'properties\\': {\\'user_emotion\\': {\\'description\\': \"User\\'s emotion while writing the query.\", \\'example\\': \\'A mix of relief, regret and sadness\\', \\'title\\': \\'User Emotion\\', \\'type\\': \\'string\\'}, \\'user_problem\\': {\\'description\\': \\'The problem/issue user is facing\\', \\'example\\': \\'self identity crisis\\', \\'title\\': \\'User Problem\\', \\'type\\': \\'string\\'}, \\'strategy\\': {\\'description\\': \"Strategy to be used to answer user\\'s query\", \\'example\\': \\'A mix of Affirmation and Reassurance and Providing Suggestions\\', \\'title\\': \\'Strategy\\', \\'type\\': \\'string\\'}, \\'output\\': {\\'description\\': \\'An output to be sent to the user\\', \\'title\\': \\'Output\\', \\'type\\': \\'string\\'}}, \\'required\\': [\\'user_emotion\\', \\'user_problem\\', \\'strategy\\', \\'output\\'], \\'title\\': \\'AnswerFormat\\', \\'type\\': \\'object\\'}\\n\\nQuery: hi\\nAnswer:\\n\\n            {\"strategy\" :'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from lmformatenforcer import JsonSchemaParser\n",
    "from lmformatenforcer.integrations.transformers import build_transformers_prefix_allowed_tokens_fn\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "class AnswerFormat(BaseModel):\n",
    "    user_emotion: str = Field(..., description=\"User's emotion while writing the query.\", example=\"A mix of relief, regret and sadness\")\n",
    "    user_problem: str = Field(..., description=\"The problem/issue user is facing\", example=\"self identity crisis\")\n",
    "    strategy: str = Field(..., description=\"Strategy to be used to answer user's query\", example=\"A mix of Affirmation and Reassurance and Providing Suggestions\")\n",
    "    output: str = Field(..., description=\"An output to be sent to the user\")\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-large\")\n",
    "\n",
    "# Parse the schema and create a prefix function\n",
    "parser = JsonSchemaParser(AnswerFormat.schema())\n",
    "prefix_function = build_transformers_prefix_allowed_tokens_fn(tokenizer, parser)\n",
    "\n",
    "# Create a Hugging Face pipeline for conversational tasks\n",
    "hf_pipeline = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    prefix_allowed_tokens_fn=prefix_function\n",
    ")\n",
    "\n",
    "# User query\n",
    "query = \"hi\"\n",
    "\n",
    "# Define the schema-based prompt\n",
    "prompt = f'''Your task is to find out the following things regarding the user's query:\n",
    "- User's emotion\n",
    "- User's problem (e.g., job crisis, loneliness, etc.)\n",
    "- A therapy strategy that will help the user the most (e.g., \n",
    "  \"Questioning to make them open up\",\n",
    "  \"Restatement or Paraphrasing\",\n",
    "  \"Reflection of feelings\",\n",
    "  \"Self-disclosure\",\n",
    "  \"Affirmation and Reassurance\",\n",
    "  \"Providing Suggestions\")\n",
    "- A human-like empathetic message\n",
    "\n",
    "Provide the result in this schema:\n",
    "{AnswerFormat.model_json_schema()}\n",
    "\n",
    "Query: {query}\n",
    "Answer:\\n'''\n",
    "\n",
    "# Generate output using the pipeline\n",
    "output_dict = hf_pipeline(prompt, max_length=500, num_return_sequences=1)\n",
    "\n",
    "# Extract the generated result\n",
    "result = output_dict[0]['generated_text'][len(prompt):]\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee9d0a1b3a44e7b9ef6d18f251e4f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e761b8b425644dcebc0d79117fb2303b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f9f25b17f645449afb1a47993222d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07 21:40:07.665798: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-07 21:40:08.450769: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-07 21:40:08.450883: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-07 21:40:08.543681: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-07 21:40:08.858192: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-07 21:40:11.492912: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-large\")\n",
    "\n",
    "# Let's chat for 5 lines\n",
    "for step in range(5):\n",
    "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
    "    print(new_user_input_ids)\n",
    "    # append the new user input tokens to the chat history\n",
    "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
    "    print(bot_input_ids)\n",
    "    # generated a response while limiting the total chat history to 1000 tokens, \n",
    "    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
    "    print(chat_history_ids)\n",
    "    # pretty print last ouput tokens from bot\n",
    "    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07 23:45:35.647864: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-07 23:45:36.199938: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-07 23:45:36.200019: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-07 23:45:36.289418: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-07 23:45:36.471525: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-07 23:45:38.519874: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from transformers import pipeline\n",
    "import faiss\n",
    "import time\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import asyncio\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil\n",
    "\n",
    "def get_gpu_usage():\n",
    "    \"\"\"\n",
    "    Get the current GPU usage as a percentage.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing GPU usage details.\n",
    "    \"\"\"\n",
    "    gpus = GPUtil.getGPUs()  # Get list of GPUs available\n",
    "    gpu_usage_info = []\n",
    "\n",
    "    for gpu in gpus:\n",
    "        gpu_info = {\n",
    "            'GPU': gpu.name,\n",
    "            'Memory Total': gpu.memoryTotal,\n",
    "            'Memory Used': gpu.memoryUsed,\n",
    "            'Memory Free': gpu.memoryFree,\n",
    "            'GPU Utilization': gpu.memoryUtil * 100,  # Memory Utilization in percentage\n",
    "            'GPU Temperature': gpu.temperature  # GPU Temperature (in Celsius)\n",
    "        }\n",
    "        gpu_usage_info.append(gpu_info)\n",
    "\n",
    "    return gpu_usage_info\n",
    "\n",
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    def __init__(self):\n",
    "        print(get_gpu_usage())\n",
    "        # self.dialo = pickle.load(open(small_model_path, \"rb\"))\n",
    "        self.problem_tokenizer = AutoTokenizer.from_pretrained(\n",
    "            \"microsoft/DialoGPT-medium\"\n",
    "        )\n",
    "        self.problem_model = AutoModel.from_pretrained(\"microsoft/DialoGPT-small\")\n",
    "        print(get_gpu_usage())\n",
    "        # self.rag = faiss.read_index(rag_path)\n",
    "        self.emotion_model = pipeline(\n",
    "            \"text-classification\", model=\"SamLowe/roberta-base-go_emotions\"\n",
    "        )\n",
    "        print(get_gpu_usage())\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        # self.strategy_tokenizer = AutoTokenizer.from_pretrained(\n",
    "        #     \"heegyu/TinyLlama-augesc-context-strategy\"\n",
    "        # )\n",
    "        print(get_gpu_usage())\n",
    "        # self.strategy_model = (\n",
    "        #     AutoModelForSequenceClassification.from_pretrained(\n",
    "        #         \"heegyu/TinyLlama-augesc-context-strategy\"\n",
    "        #     )\n",
    "        #     .eval()\n",
    "        #     .to(self.device)\n",
    "        # )\n",
    "        ESCONV_STRATEGY = [\n",
    "            \"Question\",\n",
    "            \"Restatement or Paraphrasing\",\n",
    "            \"Reflection of feelings\",\n",
    "            \"Self-disclosure\",\n",
    "            \"Affirmation and Reassurance\",\n",
    "            \"Providing Suggestions\",\n",
    "            \"Information\",\n",
    "            \"Others\",\n",
    "        ]\n",
    "        self.strategy_id2label = {i: k for i, k in enumerate(ESCONV_STRATEGY)}\n",
    "        genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "        self.model = genai.GenerativeModel(\"gemini-1.5-flash-002\")\n",
    "        print(get_gpu_usage())\n",
    "        print(\"Initialised\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'GPU': 'NVIDIA GeForce RTX 3050 Ti Laptop GPU', 'Memory Total': 4096.0, 'Memory Used': 0.0, 'Memory Free': 3962.0, 'GPU Utilization': 0.0, 'GPU Temperature': 42.0}]\n",
      "[{'GPU': 'NVIDIA GeForce RTX 3050 Ti Laptop GPU', 'Memory Total': 4096.0, 'Memory Used': 0.0, 'Memory Free': 3962.0, 'GPU Utilization': 0.0, 'GPU Temperature': 42.0}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'GPU': 'NVIDIA GeForce RTX 3050 Ti Laptop GPU', 'Memory Total': 4096.0, 'Memory Used': 609.0, 'Memory Free': 3354.0, 'GPU Utilization': 14.8681640625, 'GPU Temperature': 43.0}]\n",
      "[{'GPU': 'NVIDIA GeForce RTX 3050 Ti Laptop GPU', 'Memory Total': 4096.0, 'Memory Used': 609.0, 'Memory Free': 3354.0, 'GPU Utilization': 14.8681640625, 'GPU Temperature': 43.0}]\n",
      "[{'GPU': 'NVIDIA GeForce RTX 3050 Ti Laptop GPU', 'Memory Total': 4096.0, 'Memory Used': 609.0, 'Memory Free': 3354.0, 'GPU Utilization': 14.8681640625, 'GPU Temperature': 43.0}]\n",
      "Initialised\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Chatbot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
